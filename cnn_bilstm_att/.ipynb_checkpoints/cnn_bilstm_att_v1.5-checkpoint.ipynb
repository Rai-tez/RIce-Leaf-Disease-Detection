{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rrmGtOssK8G2",
   "metadata": {
    "id": "rrmGtOssK8G2"
   },
   "source": [
    "# Import and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1933b42a",
   "metadata": {
    "id": "1933b42a"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Reshape, Lambda, MultiHeadAttention, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Preprocessing\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray, rgb2hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063a0e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "#             SET FIRST IF USING LOCAL OR COLAB               #\n",
    "###############################################################\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "USING_LOCAL = True\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "if (USING_LOCAL):\n",
    "    # set gpu to be the one doing the computation\n",
    "    phy_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(phy_devices)\n",
    "    if phy_devices:\n",
    "        tf.config.experimental.set_memory_growth(phy_devices[0], True)\n",
    "        \n",
    "    # this folder must exist in your local where this ntbk is located\n",
    "    # the folder 'data' must contain the dir of your dataset\n",
    "#     root = '../cnn/my-first-cnn/data'\n",
    "    #root = 'data'\n",
    "    \n",
    "    #Drei's root path to datasets\n",
    "    root = 'D:/Andrei/Andrei/Prog Applications/datasets'\n",
    "else:\n",
    "    # mount google drive to get the dataset\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # set root path of the dataset\n",
    "    # create shortcut of the dataset to your own drive\n",
    "    # 'Shared with me' dir wont work\n",
    "    root = '/content/drive/skewl/Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EpTB8IGbLMg_",
   "metadata": {
    "id": "EpTB8IGbLMg_"
   },
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aJ9j_uwo2QUK",
   "metadata": {
    "id": "aJ9j_uwo2QUK"
   },
   "source": [
    "### Get datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94ec611",
   "metadata": {
    "id": "399f533b"
   },
   "outputs": [],
   "source": [
    "def get_train_X_and_Y(train_path, size=(224,224), batch_size=1):\n",
    "    train_batch = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=train_path, \n",
    "        image_size=size,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        seed = 9\n",
    "    )\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for images, labels in train_batch.take(-1):\n",
    "        X.append(images.numpy()[0,:,:,:])\n",
    "        Y.append(labels.numpy()[0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def get_train_XY_and_valid(train_path, size=(224,224), batch_size=1, split=.15):\n",
    "    train_batch = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=train_path, \n",
    "        image_size=size,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        shuffle=True,\n",
    "        validation_split=split,\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        seed = 9\n",
    "    )\n",
    "    \n",
    "    valid_batch = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=train_path, \n",
    "        image_size=size, \n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        validation_split=split,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        subset='validation',\n",
    "        seed = 9\n",
    "    )\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for images, labels in train_batch.take(-1):\n",
    "        X.append(images.numpy()[0,:,:,:])\n",
    "        Y.append(labels.numpy()[0])\n",
    "        \n",
    "    return np.array(X), np.array(Y), valid_batch\n",
    "\n",
    "\n",
    "def get_test(test_path, size=(224,224), batch_size=1):\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=test_path, \n",
    "        image_size=size, \n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a04c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_train_X_and_Y(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac399bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_1xLp9El3q7Q",
   "metadata": {
    "id": "_1xLp9El3q7Q"
   },
   "source": [
    "### Plotting batch images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500817c1",
   "metadata": {
    "id": "500817c1"
   },
   "outputs": [],
   "source": [
    "def plotImagesWithBatch(batch):\n",
    "    imgs, labels = next(batch)\n",
    "    fig, axes = plt.subplots(1,10,figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(imgs, axes):\n",
    "        ax.imshow(img/255)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e74bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    image = X[i][0,:,:,:]\n",
    "    plt.imshow(image.astype(\"uint8\"))\n",
    "    plt.title(class_names[Y[i][0]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zd7bfR0a3xo_",
   "metadata": {
    "id": "Zd7bfR0a3xo_"
   },
   "source": [
    "### Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "T25LZs2LUzXn",
   "metadata": {
    "id": "T25LZs2LUzXn"
   },
   "outputs": [],
   "source": [
    "def ReshapeLayer(x):\n",
    "    shape = x.shape\n",
    "    reshape = Reshape((shape[1],shape[2]*shape[3]))(x)\n",
    "    return reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2UVpmmxCLwoo",
   "metadata": {
    "id": "2UVpmmxCLwoo"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3hJgBIaL1SV",
   "metadata": {
    "id": "s3hJgBIaL1SV"
   },
   "source": [
    "### Set Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28267243",
   "metadata": {
    "id": "28267243"
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset_path = f'{root}/CompletePreprocess_RiceDiseaseDataset'\n",
    "#dataset_path = f'{root}/PreprocessedRiceDiseaseDataset'\n",
    "dataset_path = f'{root}/Rice diseases/RiceDiseaseDataset2'\n",
    "# dataset_path = f'{root}/PetImages_2000-500-800'\n",
    "#dataset_path = f'{root}/threshold with shadow removal 3'\n",
    "# dataset_path = f'{root}/_PlantVillage_Apple'\n",
    "# dataset_path = f'{root}/_RiceDiseaseDataset'\n",
    "\n",
    "train_path = f'{dataset_path}/training'\n",
    "\n",
    "#########################################################################\n",
    "#      MUST BE FALSE IF USING CompletePreprocess_RiceDiseaseDataset     #\n",
    "#########################################################################\n",
    "# True if using unpreprocessed data\n",
    "include_preprocessing = False\n",
    "\n",
    "#########################################################################\n",
    "#      MUST BE FALSE IF USING CompletePreprocess_RiceDiseaseDataset     #\n",
    "#########################################################################\n",
    "# False if the available folders are only Train and Testing\n",
    "dedicated_validation_folder = False\n",
    "\n",
    "if dedicated_validation_folder:\n",
    "    valid_path = f'{dataset_path}/validation'\n",
    "    test_path = f'{dataset_path}/testing'\n",
    "else:\n",
    "    test_path = f'{dataset_path}/testing'\n",
    "\n",
    "per_batch_size = 16\n",
    "size = (224, 224)\n",
    "\n",
    "class_names = ['BrownSpot', 'Healthy', 'Hispa', 'LeafBlast']\n",
    "# class_names = ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy']\n",
    "# class_names = ['dog', 'cat']\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qgNlh1PAK1S4",
   "metadata": {
    "id": "qgNlh1PAK1S4"
   },
   "outputs": [],
   "source": [
    "input_shape = (size[0], size[1], 3)\n",
    "learn_rate = 0.0001\n",
    "#learn_rate = 0.001\n",
    "# learn_rate = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oWQQtPSnL9Um",
   "metadata": {
    "id": "oWQQtPSnL9Um"
   },
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#                       MobileNet PURE                        #\n",
    "###############################################################\n",
    "def create_MobileNet_pure():\n",
    "    #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "    base_model=tf.keras.applications.MobileNet(input_shape=(224, 224, 3))\n",
    "    \n",
    "    #Start of model sequence \n",
    "    x = base_model.layers[-6].output\n",
    "    preds = Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "    \n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "    \n",
    "    l = -23\n",
    "    for layer in model.layers[:l]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[l:]:\n",
    "        layer.trainable=True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learn_rate), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "#     model.compile(optimizer=Adam(learning_rate=learn_rate), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63098943",
   "metadata": {
    "id": "63098943"
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#                   MobileNet with BiLSTM                     #\n",
    "###############################################################\n",
    "def create_MobileNet_model():\n",
    "    #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "    base_model=tf.keras.applications.MobileNet(\n",
    "        include_top=False, #will not include FC Layers\n",
    "        input_shape=(224, 224, 3),\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    #the application of tanh as an activation in BiLSTM is better than relu\n",
    "    #as it is one of the requirements to use cuDNN kernels for faster training\n",
    "    #activation[relu] = 8 seconds avg in training after 1st epoch\n",
    "    #activation[tanh] = 4 seconds avg in training after 1st epoch \n",
    "    forward_layer = LSTM(128, return_sequences=True)\n",
    "    backward_layer = LSTM(128, activation='tanh', return_sequences=True, recurrent_dropout=0, go_backwards=True)\n",
    "    \n",
    "    bilstm1 = Bidirectional(forward_layer, backward_layer = backward_layer)\n",
    "    bilstm2 = Bidirectional(LSTM(64, activation='tanh',recurrent_dropout=0))\n",
    "    \n",
    "    #Start of model sequence \n",
    "    x = base_model.output\n",
    "    x = Lambda(ReshapeLayer)(x)\n",
    "    x = bilstm1(x)\n",
    "    x = bilstm2(x)\n",
    "    \n",
    "    preds = Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "    \n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "    \n",
    "    l = -23\n",
    "    for layer in model.layers[:l]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[l:]:\n",
    "        layer.trainable=True\n",
    "\n",
    "#     model.compile(optimizer=Adam(learning_rate=learn_rate), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(learning_rate=learn_rate), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a6057",
   "metadata": {
    "id": "270a6057"
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#            MobileNet with BiLSTM and Attention              #\n",
    "###############################################################\n",
    "\n",
    "def create_MobileNet_Attention():\n",
    "    #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "    base_model=tf.keras.applications.MobileNet(\n",
    "        include_top=False, #will not include FC Layers\n",
    "        input_shape=(224, 224, 3),\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    attention = MultiHeadAttention(num_heads=2, key_dim=2)\n",
    "    \n",
    "    #the application of tanh as an activation in BiLSTM is better than relu\n",
    "    #as it is one of the requirements to use cuDNN kernels for faster training\n",
    "    #activation[relu] = 8 seconds avg in training after 1st epoch\n",
    "    #activation[tanh] = 4 seconds avg in training after 1st epoch \n",
    "    forward_layer = LSTM(128, return_sequences=True)\n",
    "    backward_layer = LSTM(128, activation='tanh', return_sequences=True, recurrent_dropout=0, go_backwards=True)\n",
    "    \n",
    "    bilstm1 = Bidirectional(forward_layer, backward_layer = backward_layer)\n",
    "    bilstm2 = Bidirectional(LSTM(64, activation='tanh',recurrent_dropout=0))\n",
    "\n",
    "    #Start of model sequence \n",
    "    x = base_model.output\n",
    "\n",
    "    x = attention(x, x, training=True)\n",
    "    \n",
    "    x = Lambda(ReshapeLayer)(x)\n",
    "    x = bilstm1(x)\n",
    "    x = bilstm2(x)\n",
    "    preds = Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "    l = -23\n",
    "    for layer in model.layers[:l]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[l:]:\n",
    "        layer.trainable=True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learn_rate), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b48deb",
   "metadata": {
    "id": "07b48deb"
   },
   "source": [
    "### Usual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15eb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#      DO NOT RUN THIS WHEN DOING CROSS VALIDATION TRAINING     #\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c039c94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c039c94",
    "outputId": "b8f64317-8118-4d5b-c6ae-e70ae839e754"
   },
   "outputs": [],
   "source": [
    "# train_batch, valid_batch = get_train_and_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910009ff",
   "metadata": {
    "id": "910009ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mn = create_MobileNet_model()\n",
    "mn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xZ8Xa4Av6Iab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "xZ8Xa4Av6Iab",
    "outputId": "a6109979-0ce5-43c5-d793-f2d534bcc2e7"
   },
   "outputs": [],
   "source": [
    "# plotImagesWithBatch(train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9354e2",
   "metadata": {
    "id": "5a9354e2"
   },
   "outputs": [],
   "source": [
    "# model_history = mn.fit(x=train_batch, validation_data=valid_batch, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76dbb8",
   "metadata": {
    "id": "dc76dbb8"
   },
   "source": [
    "### 5-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2731b9b7",
   "metadata": {
    "id": "2731b9b7"
   },
   "outputs": [],
   "source": [
    "model_label = 'mnet_bilstm_rice_kfolded'\n",
    "\n",
    "# set early stopping criteria\n",
    "pat = 5 # this is the number of epochs with no improvment after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1, baseline=None)\n",
    "\n",
    "# define the model checkpoint callback -> this will keep on saving the model as a physical file\n",
    "model_checkpoint = ModelCheckpoint(f'model_checkpoints/{model_label}.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# to save the history of models\n",
    "csv_logger = CSVLogger(f'logs/{model_label}.log', separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c2abc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#save the model history in a list after fitting so that we can plot later\n",
    "model_history = []\n",
    "model_eval_score = []\n",
    "\n",
    "n_folds=5\n",
    "epochs=100\n",
    "batch_size=32\n",
    "\n",
    "loaded_model_file_path = 'model_checkpoints/'\n",
    "loaded_model_file_name = model_label\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "X, Y = get_train_X_and_Y(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ebf7f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 ... 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c0a3aba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c0a3aba",
    "outputId": "d648ecfb-bd6d-4726-e1fb-eb7a2d943efa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold: 1\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 21s 268ms/step - loss: 1.2133 - accuracy: 0.4330 - val_loss: 1.4158 - val_accuracy: 0.3073\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.41583, saving model to model_checkpoints\\mnet_bilstm_rice_kfolded.h5\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 4s 132ms/step - loss: 0.6314 - accuracy: 0.8348 - val_loss: 1.2960 - val_accuracy: 0.3594\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.41583 to 1.29602, saving model to model_checkpoints\\mnet_bilstm_rice_kfolded.h5\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 4s 133ms/step - loss: 0.2614 - accuracy: 0.9866 - val_loss: 1.1784 - val_accuracy: 0.4609\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29602 to 1.17841, saving model to model_checkpoints\\mnet_bilstm_rice_kfolded.h5\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 4s 139ms/step - loss: 0.0833 - accuracy: 0.9978 - val_loss: 1.3672 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17841\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 4s 133ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.2782 - val_accuracy: 0.4844\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17841\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 4s 133ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.4948\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17841\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 4s 154ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3779 - val_accuracy: 0.5234\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17841\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 4s 154ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.5286\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.17841\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "Evaluating on Fold 2:\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_2/conv_pw_1_bn/FusedBatchNormV3 (defined at \\AppData\\Local\\Temp\\ipykernel_7936\\1113228649.py:11) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_33324]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m model_history\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     12\u001b[0m     X[train], Y[train],\n\u001b[0;32m     13\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     19\u001b[0m ))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating on Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m model_eval_score\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=======\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1504\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1503\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1504\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1505\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1506\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    926\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    927\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_2/conv_pw_1_bn/FusedBatchNormV3 (defined at \\AppData\\Local\\Temp\\ipykernel_7936\\1113228649.py:11) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_33324]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, valid in kfold.split(X, Y):\n",
    "    print(f\"Training on Fold: {fold_no}\")\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    model = create_MobileNet_model()\n",
    "\n",
    "    model_history.append(model.fit(\n",
    "        X[train], Y[train],\n",
    "        validation_split=.3,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping, model_checkpoint, csv_logger],\n",
    "        verbose=1,\n",
    "        shuffle = True\n",
    "    ))\n",
    "    \n",
    "    print(f\"\\nEvaluating on Fold {fold_no}:\")\n",
    "    \n",
    "    model_eval_score.append(model.evaluate(X[valid], Y[valid], batch_size=batch_size, verbose=1))\n",
    "    \n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CJzN_sU6MsbL",
   "metadata": {
    "id": "CJzN_sU6MsbL"
   },
   "source": [
    "# Prediction and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c635b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading h5 file or the model that has undergon cross validation\n",
    "saved_model_file_path = 'model_checkpoints/'\n",
    "saved_model_file_name = model_label\n",
    "saved_model = tf.keras.models.load_model(saved_model_file_path + saved_model_file_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85dfea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_batch.classes\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = saved_model.predict(x=test_batch, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ARGMAX = y_pred.argmax(axis=1)\n",
    "y_pred_ARGMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8746f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.stackvidhya.com/plot-confusion-matrix-in-python-and-why/\n",
    "#Confusion Matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_ARGMAX)\n",
    "ax = sb.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
    "ax.set_title('Confusion Matrix\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ')\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0073f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69846954",
   "metadata": {
    "id": "69846954"
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred_ARGMAX, average = None)\n",
    "accuracy = accuracy_score(y_test, y_pred_ARGMAX)\n",
    "recall = recall_score(y_test, y_pred_ARGMAX, average = None)\n",
    "f1 = f1_score(y_test, y_pred_ARGMAX, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Precision: %.3f' % precision)\n",
    "#print('Accuracy: %.3f' % accuracy)\n",
    "#print('Recall: %.3f' % recall)\n",
    "#print('F1-Score: %.3f' % f1)\n",
    "format = {}\n",
    "\n",
    "for n in range(len(class_names)):\n",
    "    format[class_names[n]] = [precision[n]* 100, recall[n]* 100, f1[n]* 100]\n",
    "    \n",
    "df = pd.DataFrame(format, ['Precision', 'Recall', 'F1']).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad07087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.evaluate(x=test_batch, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d4959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cnn-bilstm-att.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
